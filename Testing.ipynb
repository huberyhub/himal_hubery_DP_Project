{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2ForSequenceClassification, GPT2Config\n",
    "\n",
    "# Load the tokenizer and configuration\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('model_tokenizer')\n",
    "config = GPT2Config.from_pretrained('model_tokenizer')\n",
    "\n",
    "# Initialize the model\n",
    "model = GPT2ForSequenceClassification.from_pretrained('model_tokenizer', config=config)\n",
    "\n",
    "# Load the trained model weights\n",
    "model.load_state_dict(torch.load('gpt2_sentiment_analysis.pth'))\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "model.to(torch.device(\"cuda\" if torch.cuda.is available() else \"cpu\"))\n",
    "\n",
    "# Prediction function\n",
    "def predict_headline(headline, tokenizer, model, device):\n",
    "    model.eval()  # Ensure the model is in evaluation mode\n",
    "    inputs = tokenizer.encode_plus(\n",
    "        headline, \n",
    "        return_tensors=\"pt\", \n",
    "        max_length=512, \n",
    "        truncation=True, \n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "\n",
    "    input_ids = inputs['input_ids'].to(device)\n",
    "    attention_mask = inputs['attention_mask'].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        prediction = torch.argmax(outputs.logits, dim=-1)\n",
    "\n",
    "    return \"Increase\" if prediction == 1 else \"Decrease\"\n",
    "\n",
    "# Example usage\n",
    "headline = \"Stock market hits new record high as investor confidence soars.\"\n",
    "print(predict_headline(headline, tokenizer, model, torch.device(\"cpu\")))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
